---
# Goal: Create pvcs using topology aware storage class and confirms they behave as expected
- name: re-create {{ cinder_csi_project_name }} project
  include_role:
    name: ocp_project
    tasks_from: recreate_ocp_project.yml
  vars:
    project_name: "{{ cinder_csi_project_name }}"
    force_delete: true

### Evaluate existing environment and define below variables to be used on the new resources:
# - number_of_workers [int]: for iteration.
# - nova_az_for_sc [list]: ordered by worker, indicates the nova zone for that worker.
# - cinder_az_for_sc [list]: ordered by worker, indicates the cinder zone for that worker.
#     If no cinder az is found for a worker default one 'nova' is assumed.
- name: reset variables
  set_fact:
    worker_names: []
    nova_az_for_sc: []
    cinder_az_for_sc: []
    existing_pvc_azs: []

- name: Get existing workers
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Node
    label_selectors:
      - node-role.kubernetes.io/worker
  register: workers

- name: declare list of workers names and their nova zone
  set_fact:
    worker_names: "{{ worker_names|default([]) + [ item.metadata.labels['kubernetes.io/hostname'] ] }}"
    nova_az_for_sc: "{{ nova_az_for_sc|default([]) + [ item.metadata.labels['topology.cinder.csi.openstack.org/zone'] ] }}"
  loop: "{{ workers.resources | sort(attribute='metadata.name') | list }}"
  no_log: true

- name: set number of workers
  set_fact:
    number_of_workers: "{{ worker_names | length }}"

- name: get volume az for workers (if any)
  shell: |
    openstack volume show $(openstack volume list -c ID -c Name -f value | grep "{{ item }}" | cut -d' ' -f2) -c availability_zone -f value
  environment:
    OS_CLOUD: "{{ user_cloud }}"
  loop: "{{ worker_names }}"
  register: temporary_output
  ignore_errors: yes

- name: convert output on a list
  set_fact:
    cinder_az_for_sc: "{{ cinder_az_for_sc + [item.stdout if item.stdout != '' else 'nova'] }}"
  loop: "{{ temporary_output.results | list }}"
  when: edge_nova_az is not defined

# At the Edge environment, the Cinder AZ name is identical to the Nova AZ.
# There is no need to look it up.
- name: Set the Cinder AZ parameter (Edge case)
  set_fact:
    cinder_az_for_sc: "{{ [edge_nova_az] * (number_of_workers | int) }}"
  when: edge_nova_az is defined

### Create & apply manifests:
#  - New storageClass with each AZ pairing (per worker) is created.
#  - A pvc using the new storageClass is created.
#  - The pods are instructed to be scheduled on the appropiate nova AZ.

- name: Remove existing topologyaware storageclases
  kubernetes.core.k8s:
    state: absent
    api_version: storage.k8s.io/v1
    kind: StorageClass
    name: topology-aware-{{item}}
  loop: "{{ range(number_of_workers | int) | list }}"

- name: create manifests for {{ cinder_csi_project_name }} namespace
  template:
    src: cinder_csi.manifests.yaml.j2
    dest: "{{ home_dir }}/cinder_csi_{{item}}.yaml"
  loop: "{{ range(number_of_workers | int) | list }}"

- name: Apply manifests for {{ cinder_csi_project_name }} namespace and check they are running.
  kubernetes.core.k8s:
    state: present
    src: "{{ home_dir }}/cinder_csi_{{item}}.yaml"
    wait: yes
    wait_timeout: "{{ manifests_wait_timeout }}"
  loop: "{{ range(number_of_workers | int) | list }}"

# Check that one cinder volume per PVC is created on openstack
- name: Get created PVCs
  kubernetes.core.k8s_info:
    kind: pvc
    namespace: "{{ cinder_csi_project_name }}"
  register: existing_pvcs

- set_fact:
    existing_pvc_ids: "{{ existing_pvcs | json_query('resources[].spec.volumeName') | list }}"

- name: get cinder volumes for PVCs
  shell: |
    openstack volume show "{{ item }}" -c availability_zone -f value
  environment:
    OS_CLOUD: "{{ user_cloud }}"
  loop: "{{ existing_pvc_ids }}"
  register: temporary_output

- name: convert output on a list
  set_fact:
    existing_pvc_azs: "{{ existing_pvc_azs + [item.stdout] }}"
  loop: "{{ temporary_output.results | list }}"

- name: Check - expected cinder AZs on PVCs
  assert:
    that:
    - existing_pvc_azs[item] == cinder_az_for_sc[item]
    fail_msg: |
      unexpected cinder AZs created for PVCs:
      List expected AZs for PVCs: {{cinder_az_for_sc}}
      List obtained AZs for PVCs: {{existing_pvc_azs}}
  loop: "{{ range(number_of_workers | int) | list }}"

# Check that writes on the PVC are persistent (ReadWriteOnce)
- name: Get pod names
  kubernetes.core.k8s_info:
    kind: Pod
    namespace: "{{ cinder_csi_project_name }}"
  register: demo_pods

- name: store name of pods
  set_fact:
    pod_names: "{{ demo_pods | json_query('resources[*].metadata.name') | list }}"

- name: create file on the PVC running on the pod
  shell: "oc exec -t {{ pod_names[item] }} -n {{ cinder_csi_project_name }} -- touch /var/lib/www/data/hello-{{item}}"
  loop: "{{ range(number_of_workers | int) | list }}"

- name: Delete pods
  kubernetes.core.k8s:
    api_version: v1
    kind: Pod
    namespace: "{{ cinder_csi_project_name }}"
    name: "{{ item }}"
    state: absent
    wait: yes
    wait_timeout: 60
  loop: "{{ pod_names }}"

- name: Get recreated pod names
  kubernetes.core.k8s_info:
    kind: Pod
    namespace: "{{ cinder_csi_project_name }}"
    field_selectors:
      - status.phase=Running
  register: demo_pods
  retries: 15
  delay: 15
  until: demo_pods.resources|length == number_of_workers|int

- name: store name of pods after recreation
  set_fact:
    pod_names: "{{ demo_pods | json_query('resources[*].metadata.name') | list }}"

- name: read file on the PVC running on the pod
  shell: "oc exec -t {{ pod_names[item] }} -n {{ cinder_csi_project_name }} -- ls /var/lib/www/data/hello-{{item}}"
  loop: "{{ range(number_of_workers | int) | list }}"
